# Exaone 3.5 7.8B vs Llama 3.1 8B 비교 분석

## 개요

본 문서는 응급실 Clinical Note 생성을 위해 두 가지 로컬 LLM 모델인 **Exaone 3.5 7.8B**와 **Llama 3.1 8B**를 비교 분석한 결과를 정리합니다.

두 모델 모두 Ollama를 통해 로컬에서 실행되며, 완전 무료로 사용 가능합니다.

테스트 환경:
- 환자 데이터: 2명 (R-1731-00000001, R-1731-00000034)
- 생성 언어: 한글, 영어 각 1개씩 (총 4개/모델)
- 프레임워크: AutoGen
- 형식: Primary Consultation

---

분석 목표

1. **한글 성능 비교**: 한국어 의료 문서 생성 품질
2. **정확도 비교**: 환자 데이터 반영의 정확성
3. **형식 준수**: Primary Consultation 형식 준수 여부
4. **실전 활용성**: 실제 응급실 환경에서의 활용 가능성

---

모델 정보

1) Exaone 3.5 7.8B

- 개발: LG AI Research
- 특징: 한영 이중언어 특화 모델
- 파라미터: 7.8B
- 모델 크기: 4.8GB
- 강점: 한국어 자연어 생성 우수

설정 파일: `Local_LLM/Exaone_LLM/config/config.py:10-16`
```python
LLM_CONFIG = {
    "model": "exaone3.5:7.8b",
    "base_url": "http://localhost:11434/v1",
    "temperature": 0.7,
    "max_tokens": 2000
}
```

# Llama 3.1 8B

- 개발: Meta
- 특징: 범용 언어 모델
- 파라미터: 8B
- 모델 크기: 4.7GB
- 강점: 일관된 성능, 안정성

설정 파일: `Local_LLM/Admin_Agent_Local/config/config.py:10-16`
```python
LLM_CONFIG = {
    "model": "llama3.1:8b",
    "base_url": "http://localhost:11434/v1",
    "temperature": 0.7,
    "max_tokens": 2000
}
```

---

## 비교 분석 결과

### 1. 환자 R-1731-00000001 (78세 여성, 어깨 장애 증후군)

* 한글 버전 비교

| 평가 항목 | Exaone 3.5 7.8B | Llama 3.1 8B |
|---------|----------------|--------------|
| **형식 준수** | 완벽 | 완벽 |
| **한글 자연스러움** | 5 | 4 |
| **오타/한자 혼용** | X | O ("근육緊張감", "부진 단명") |
| **정보 정확도** | 4 | 5 |
| **상세함** | 5 | 3 |

Exaone 장점:
- 매우 자연스러운 한글 표현
- 환자 중심의 서술 ("환자 조**는...")
- 상세하고 전문적인 내용
- 오타 없음

Exaone 단점:
- 진단명 코드 오류 (S22440을 어깨 증후군으로 표기)
- 데이터에 없는 내용 추가 가능성 ("갑작스러운 흉통")

Llama 장점:
- 정보 정확도 높음
- 진단명 정확

Llama 단점:
- 한자 혼용 ("緊張감")
- 오타 ("부진 단명" → "부진단명")

**생성 파일:**
- Exaone: `data/output_notes/R-1731-00000001_korean_exaone_20251116_213042.txt`
- Llama: `../Admin_Agent_Local/data/output_notes/R-1731-00000001_korean_llama_20251116_070733.txt`

---

#### 영어 버전 비교

| 평가 항목 | Exaone 3.5 7.8B | Llama 3.1 8B |
|---------|----------------|--------------|
| **전문성** | 5 | 5 |
| **정보 정확도** | 5 | 5 |
| **언어 순수성** | 4 | 4 |

**Exaone 장점:**
- 매우 전문적인 의학 용어 사용
- 상세한 설명

**Exaone 단점:**
- 문서 마지막에 한글 메시지 포함 (언어 혼용)

**Llama 장점:**
- 영어만 사용 (언어 혼용 없음)
- 정보 정확

**생성 파일:**
- Exaone: `data/output_notes/R-1731-00000001_english_exaone_20251116_213515.txt`
- Llama: `../Admin_Agent_Local/data/output_notes/R-1731-00000001_english_llama_20251116_071017.txt`

---

### 2. 환자 R-1731-00000034 (85세 남성, AECOPD)

#### 한글 버전 비교

| 평가 항목 | Exaone 3.5 7.8B | Llama 3.1 8B |
|---------|----------------|--------------|
| **형식 준수** | 1 (심각한 문제) | 2 |
| **한글 품질** | 5 | 3 |
| **정보 정확도** | 2 (날짜 오류) | 4 |
| **일관성** | 1 (환자1과 다름) | 3 |

**Exaone 치명적 문제:**
1. **형식 완전히 무시**: Primary Consultation 형식을 따르지 않음
2. **다른 구조 사용**: "임상 노트"라는 제목으로 완전히 다른 구조
3. **환자 1과 불일치**: 같은 프롬프트인데 환자마다 다른 형식
4. **날짜 오류**: "2023년 2월 11일" (실제는 2018년)
5. **환자 이름 노출**: "김**" (프라이버시 문제)

**Exaone 긍정적 측면:**
- 한글 품질은 여전히 우수
- 매우 상세하고 전문적
- 치료 계획까지 포함 (요청하지 않았지만 유용)

**Llama 문제:**
- Primary Consultation 형식 미흡
- 단순 데이터 나열
- 한자 혼용 ("胸部", "інтер벌")

**Llama 긍정적 측면:**
- AECOPD 진단명 정확
- 정보 누락 없음

**생성 파일:**
- Exaone: `data/output_notes/R-1731-00000034_korean_exaone_20251116_214408.txt`
- Llama: `../Admin_Agent_Local/data/output_notes/R-1731-00000034_korean_llama_20251116_071635.txt`

---

## 📈 종합 평가

### 정량적 비교

| 평가 항목 | Exaone 3.5 7.8B | Llama 3.1 8B | 승자 |
|---------|----------------|--------------|------|
| **한글 자연스러움** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 🏆 Exaone |
| **영어 전문성** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 동등 |
| **형식 일관성** | ⭐⭐ | ⭐⭐⭐ | 🏆 Llama |
| **정보 정확도** | ⭐⭐⭐ | ⭐⭐⭐⭐ | 🏆 Llama |
| **오류 없음** | ⭐⭐⭐ | ⭐⭐⭐⭐ | 🏆 Llama |
| **상세함** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | 🏆 Exaone |
| **한글 오타 없음** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | 🏆 Exaone |

### 정성적 평가

#### Exaone 3.5 7.8B 특징

**압도적 강점:**
1. 🏆 **한글 특화**: 한국어 모델답게 매우 자연스러운 표현
2. 🏆 **풍부한 서술**: 상세하고 전문적인 내용
3. 🏆 **오타 없음**: 한글 표현이 완벽
4. 🏆 **임상적 맥락**: 실제 의료 상황을 잘 반영

**치명적 약점:**
1. ❌ **형식 불일관성**: 환자마다 다른 형식 사용
2. ❌ **정보 추가/변경**: Hallucination 가능성
3. ❌ **날짜 오류**: 심각한 정확도 문제
4. ❌ **코드 오류**: 진단명 코드 혼동

#### Llama 3.1 8B 특징

**강점:**
1. ✅ **정보 정확도**: 데이터를 정확히 반영
2. ✅ **진단명 정확**: 의학 코드 정확
3. ✅ **일관성**: 환자마다 비슷한 접근

**약점:**
1. ❌ **한자/오타**: "緊張감", "胸部", "інтер벌"
2. ❌ **형식 미준수**: Primary Consultation 형식 불완전
3. ⚠️ **장황함**: 불필요하게 긴 문장

---

## 💡 실전 활용 권장사항

### 시나리오별 추천

#### 1. 한글 Clinical Note 생성 (품질 중시)
- 🏆 **추천: Exaone 3.5 7.8B**
- **이유**: 자연스러운 한글, 높은 전문성
- ⚠️ **주의**: 정보 정확도 검증 필수!
- **적용**: 사람이 검토하는 환경

#### 2. 영어 Clinical Note 생성
- 🏆 **추천: 동등** (둘 다 우수)
- **Exaone**: 약간 더 상세함
- **Llama**: 정보 정확도 높음

#### 3. 대량 자동 생성 (정확도 중요)
- 🏆 **추천: Llama 3.1 8B**
- **이유**: 정보 정확도, 오류 적음
- **비용**: $0 (무료)
- **적용**: 자동화된 파이프라인

#### 4. 고품질 한글 문서 (검증 가능)
- 🏆 **추천: Exaone 3.5 7.8B**
- **조건**: 사람이 검증할 수 있는 환경
- **장점**: 가장 자연스러운 한글

---

## 🔍 중요한 발견

### 형식 일관성 문제

두 모델 모두 **Primary Consultation 형식을 완벽하게 따르지 못함**:
- **Exaone**: 환자 1은 완벽, 환자 2는 완전히 다른 형식
- **Llama**: 두 환자 모두 형식 미흡

**원인 추정:**
- 프롬프트의 지시사항이 충분히 강하지 않음
- Few-shot 예시가 필요할 수 있음
- 로컬 모델의 instruction-following 능력 한계

**개선 방안:**
1. **Few-shot prompting**: 실제 Clinical Note 예시 제공
2. **형식 검증 로직**: 생성 후 자동 검증
3. **GPT-4 후처리**: 형식 보정을 위한 추가 단계
4. **프롬프트 강화**: 더 명확하고 구체적인 지시사항

### Hallucination 문제

**Exaone에서 발견된 문제:**
- 환자 1: "갑작스러운 흉통" (데이터에 없는 내용)
- 환자 2: 날짜 오류 (2023년 → 실제 2018년)

**대응 방안:**
- 사람의 검토 필수
- 자동 사실 확인 시스템
- Temperature 낮추기 (0.7 → 0.3)

---

## 🎭 하이브리드 접근 전략

실전에서 두 모델의 장점을 결합하는 전략:

```
1단계: Exaone 3.5 7.8B로 초안 생성
  ↓ (한글 품질 우수)

2단계: Llama 3.1 8B로 정확도 검증
  ↓ (정보 정확성 확인)

3단계: 사람이 최종 검토
  ↓ (형식 및 내용 보정)

완성!
```

**장점:**
- Exaone의 우수한 한글 활용
- Llama의 정확도로 검증
- 비용: $0 (완전 무료)

---

## ⚠️ 분석의 제한점

### 1. 데이터 제한
- **샘플 크기**: 환자 2명만 테스트
- **통계적 유의성**: 작은 샘플로 인한 한계
- **다양성 부족**: 다양한 진단명 미포함

### 2. 방법론적 제한
- **프롬프트**: 동일한 프롬프트 사용 (최적화되지 않음)
- **Temperature**: 0.7 고정 (다른 값 미테스트)
- **Few-shot**: 예시 없이 테스트

### 3. 해석상 주의점
- 소수 샘플의 결과를 일반화하기 어려움
- 환자 특성에 따라 결과가 달라질 수 있음
- 프롬프트 개선으로 성능 향상 가능

---

## 📊 최종 점수 및 추천

### 종합 점수

| 모델 | 총점 | 추천도 | 비고 |
|------|------|--------|------|
| **Exaone 3.5 7.8B** | ⭐⭐⭐⭐ (4/5) | 한글 특화 용도 | 검증 필수 |
| **Llama 3.1 8B** | ⭐⭐⭐⭐ (4/5) | 정확도 중요 시 | 안정적 |

### 최종 추천

**한글 Clinical Note 생성:**
- 1순위: Exaone 3.5 7.8B (검증 가능 시)
- 2순위: Llama 3.1 8B (자동화 시)

**영어 Clinical Note 생성:**
- 동등 (상황에 따라 선택)

**대량 처리:**
- Llama 3.1 8B (안정성, 정확도)

---

## 🔗 관련 파일

### 설정 파일
- Exaone: `config/config.py`
- Llama: `../Admin_Agent_Local/config/config.py`

### 실행 스크립트
- Exaone: `scripts/admin_agent_exaone.py`
- Llama: `../Admin_Agent_Local/scripts/admin_agent_local.py`

### 생성 결과
- Exaone 결과: `data/output_notes/R-1731-*_exaone_*.txt`
- Llama 결과: `../Admin_Agent_Local/data/output_notes/R-1731-*_llama_*.txt`

---

## 📚 참고 자료

- [Exaone 3.5 공식 문서](https://ollama.com/library/exaone3.5)
- [Llama 3.1 모델 카드](https://ollama.com/library/llama3.1)
- [Ollama 공식 문서](https://ollama.com/docs)
- [AutoGen Documentation](https://microsoft.github.io/autogen/)

---

## 🔄 업데이트 이력

| 날짜 | 버전 | 변경사항 |
|------|------|---------|
| 2025-01-16 | 1.0 | 초기 비교 분석 문서 작성 |

---

**작성일**: 2025-01-16
**작성자**: Multi-Agent EME 프로젝트 팀
**테스트 환경**: Windows 11, Ollama, AutoGen
**모델 버전**: Exaone 3.5 7.8B, Llama 3.1 8B
