# π€ Ollama μ„¤μΉ κ°€μ΄λ“ (Windows)

## π“¥ 1λ‹¨κ³„: Ollama λ‹¤μ΄λ΅λ“

### μλ™ λ‹¤μ΄λ΅λ“ (PowerShell)
```powershell
# PowerShellμ—μ„ μ‹¤ν–‰
Start-Process "https://ollama.com/download/windows"
```

### μλ™ λ‹¤μ΄λ΅λ“
1. λΈλΌμ°μ €μ—μ„ https://ollama.com/download/windows μ ‘μ†
2. **OllamaSetup.exe** λ‹¤μ΄λ΅λ“
3. λ‹¤μ΄λ΅λ“ν• νμΌ μ‹¤ν–‰

---

## π”§ 2λ‹¨κ³„: Ollama μ„¤μΉ

1. **OllamaSetup.exe** λ”λΈ”ν΄λ¦­
2. μ„¤μΉ λ§λ²•μ‚¬ μ§„ν–‰ (Next β†’ Next β†’ Install)
3. μ„¤μΉ μ™„λ£ ν›„ **Ollama μ„λΉ„μ¤ μλ™ μ‹μ‘**
4. μ‹μ¤ν… νΈλ μ΄μ— Ollama μ•„μ΄μ½ ν™•μΈ

---

## β… 3λ‹¨κ³„: μ„¤μΉ ν™•μΈ

### λ…λ Ή ν”„λ΅¬ν”„νΈμ—μ„ ν™•μΈ
```bash
ollama --version
```

**μμƒ μ¶λ ¥:**
```
ollama version 0.x.x
```

### Ollama μ„λ²„ ν™•μΈ
```bash
# λΈλΌμ°μ €μ—μ„ μ ‘μ†
http://localhost:11434
```

**μμƒ μ¶λ ¥:**
```
Ollama is running
```

---

## π“¦ 4λ‹¨κ³„: Llama 3.1 8B λ‹¤μ΄λ΅λ“

```bash
ollama pull llama3.1:8b
```

**μ§„ν–‰ μƒν™©:**
```
pulling manifest
pulling 8934d96d3f08... 100%
pulling 8c17c2ebb0ea... 100%
pulling 7c23fb36d801... 100%
pulling 2e0493f67d0c... 100%
pulling fa304d675061... 100%
pulling 42ba7f8a01dd... 100%
verifying sha256 digest
writing manifest
success
```

- **μ†μ” μ‹κ°„**: 5-15λ¶„ (μΈν„°λ„· μ†λ„μ— λ”°λΌ)
- **λ‹¤μ΄λ΅λ“ ν¬κΈ°**: μ•½ 4.7GB

---

## π§ 5λ‹¨κ³„: λ¨λΈ ν…μ¤νΈ

```bash
ollama run llama3.1:8b
```

**λ€ν™”ν• μΈν„°νμ΄μ¤ μ‹¤ν–‰:**
```
>>> μ•λ…•ν•μ„Έμ”
μ•λ…•ν•μ„Έμ”! λ¬΄μ—‡μ„ λ„μ™€λ“λ¦΄κΉμ”?

>>> /bye
```

---

## π― 6λ‹¨κ³„: Admin Agent Local μ‹¤ν–‰ μ¤€λΉ„ μ™„λ£!

μ„¤μΉκ°€ μ™„λ£λλ©΄ λ‹¤μ λ…λ ΉμΌλ΅ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤:

```bash
cd Local_LLM/Admin_Agent_Local/scripts
python admin_agent_local.py
```

---

## β™οΈ λ¬Έμ  ν•΄κ²°

### Ollama μ„λΉ„μ¤κ°€ μ‹μ‘λμ§€ μ•λ” κ²½μ°

**λ°©λ²• 1: μλ™μΌλ΅ μ„λΉ„μ¤ μ‹μ‘**
```bash
ollama serve
```

**λ°©λ²• 2: Windows μ„λΉ„μ¤ ν™•μΈ**
1. `Win + R` β†’ `services.msc` μ…λ ¥
2. "Ollama" μ„λΉ„μ¤ μ°ΎκΈ°
3. μ°ν΄λ¦­ β†’ μ‹μ‘

### λ¨λΈ λ‹¤μ΄λ΅λ“ μ‹¤ν¨

**μΈν„°λ„· μ—°κ²° ν™•μΈ:**
```bash
ping ollama.com
```

**λ””μ¤ν¬ κ³µκ°„ ν™•μΈ:**
- μµμ† 10GB μ΄μƒμ μ—¬μ  κ³µκ°„ ν•„μ”

### "ollama: command not found" μ¤λ¥

**ν™κ²½ λ³€μ ν™•μΈ:**
1. `Win + R` β†’ `sysdm.cpl` μ…λ ¥
2. κ³ κΈ‰ β†’ ν™κ²½ λ³€μ
3. Pathμ— Ollama κ²½λ΅ μ¶”κ°€:
   - `C:\Users\[μ‚¬μ©μλ…]\AppData\Local\Programs\Ollama`

---

## π“ μ‹μ¤ν… μ”κµ¬μ‚¬ν•­

### μµμ† μ‚¬μ–‘
- **OS**: Windows 10/11
- **RAM**: 8GB
- **λ””μ¤ν¬**: 10GB μ—¬μ  κ³µκ°„
- **CPU**: Intel Core i5 λλ” AMD Ryzen 5 μ΄μƒ

### κ¶μ¥ μ‚¬μ–‘
- **RAM**: 16GB μ΄μƒ
- **λ””μ¤ν¬**: 20GB μ—¬μ  κ³µκ°„
- **GPU**: NVIDIA GPU (μ„ νƒ, 10-20λ°° μ†λ„ ν–¥μƒ)
  - CUDA μ§€μ› GPU
  - 4GB VRAM μ΄μƒ

---

## π€ λΉ λ¥Έ μ‹μ‘ μ²΄ν¬λ¦¬μ¤νΈ

- [ ] Ollama λ‹¤μ΄λ΅λ“
- [ ] Ollama μ„¤μΉ
- [ ] `ollama --version` ν™•μΈ
- [ ] `ollama pull llama3.1:8b` μ‹¤ν–‰
- [ ] `ollama list` λ΅ λ¨λΈ ν™•μΈ
- [ ] `ollama run llama3.1:8b` ν…μ¤νΈ
- [ ] Admin Agent Local μ‹¤ν–‰ μ¤€λΉ„ μ™„λ£!

---

## π“ μ¶”κ°€ μλ£

- [Ollama κ³µμ‹ λ¬Έμ„](https://github.com/ollama/ollama/blob/main/README.md)
- [Llama 3.1 λ¨λΈ μΉ΄λ“](https://ollama.com/library/llama3.1)
- [Windows μ„¤μΉ κ°€μ΄λ“](https://github.com/ollama/ollama/blob/main/docs/windows.md)

---

**λ‹¤μ λ‹¨κ³„**: μ„¤μΉκ°€ μ™„λ£λλ©΄ `check_ollama.py`λ¥Ό μ‹¤ν–‰ν•μ—¬ μ„¤μΉ μƒνƒλ¥Ό ν™•μΈν•μ„Έμ”!

```bash
python Local_LLM/check_ollama.py
```
